version: '3.8'

# Profile options:
# - cpu: Run with Ollama on CPU only
# - gpu-nvidia: Run with Ollama on NVIDIA GPU
# - gpu-amd: Run with Ollama on AMD GPU  
# - no-ollama: Run without Ollama (external Ollama or no AI features)
# - Default (no profile): Run without Ollama services

x-n8n: &service-n8n
  image: n8nio/n8n:latest
  networks: ['ai_network']
  environment:
    - DB_TYPE=postgresdb
    - DB_POSTGRESDB_HOST=postgres
    - DB_POSTGRESDB_PORT=5432
    - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
    - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_PERSONALIZATION_ENABLED=false
    - OLLAMA_HOST=${OLLAMA_HOST:-external-ollama:11434}
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
    - N8N_DEFAULT_BINARY_DATA_MODE=${N8N_DEFAULT_BINARY_DATA_MODE}
  env_file:
    - .env
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  networks: ['ai_network']
  restart: unless-stopped
  ports:
    - 11434:11434
  volumes:
    - ollama_storage:/root/.ollama
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  container_name: ollama-pull-llama
  networks: ['ai_network']
  volumes:
    - ollama_storage:/root/.ollama
  entrypoint: /bin/sh
  environment:
    - OLLAMA_HOST=ollama:11434
  command:
    - "-c"
    - "sleep 3; ollama pull llama3.2"
#    - "sleep 3; ollama pull deepseek-r1:70b-llama-distill-q8_0"

services:
  ai_meeting_backend:
    image: jccatomind/ai_meeting_backend:latest
    container_name: ai_meeting_backend
    restart: unless-stopped
    ports:
      - "8001:8000"
    environment:
      - PORT=8000
      - FLASK_APP=app.py
      - FLASK_ENV=production
      - GUNICORN_CMD_ARGS=--timeout=300 --workers=2 --threads=4 --worker-class=gthread
      - AZURE_STT_API_KEY=${AZURE_STT_API_KEY}
      - FANOLAB_HOST=${FANOLAB_HOST}
      - FANOLAB_API_KEY=${FANOLAB_API_KEY}
      - AZURE_POSTGRES_CONNECTION=${AZURE_POSTGRES_CONNECTION}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - ON_PREMISES_MODE=${ON_PREMISES_MODE}
      - NGROK_PUBLIC_MODE=${NGROK_PUBLIC_MODE}
      - NGROK_HOST=${NGROK_HOST}
      - NGROK_ACCESS_KEY=${NGROK_ACCESS_KEY}
      - NGROK_SECRET_KEY=${NGROK_SECRET_KEY}
      - TFLOW_HOST=${TFLOW_HOST}
      - ON_PREMISES_POSTGRES_CONNECTION=${ON_PREMISES_POSTGRES_CONNECTION}
      - OLLAMA_HOST=${OLLAMA_HOST:-external-ollama:11434}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - MINIO_SECURE=false
      - MINIO_BUCKET_NAME=${MINIO_BUCKET_NAME:-meeting-minutes}
    env_file:
      - .env
    depends_on:
      pgvector:
        condition: service_healthy
      minio:
        condition: service_healthy
      n8n:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  pgvector:
    image: pgvector/pgvector:pg17
    container_name: pgvector
    environment:
      - POSTGRES_USER=${PGVECTOR_USER:-sqladmin}
      - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD:-P@ssw0rd}
      - POSTGRES_DB=${PGVECTOR_DB:-postgres}
    ports:
      - "5434:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./init-schema.sql:/docker-entrypoint-initdb.d/init-schema.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${PGVECTOR_USER:-sqladmin}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  minio:
    image: minio/minio:RELEASE.2025-06-13T11-33-47Z
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
      - minio_config:/root/.minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "5433:5432"
    volumes:
      - postgres_n8n_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  n8n-import:
    <<: *service-n8n
    container_name: n8n-import
    hostname: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/demo-data/credentials && n8n import:workflow --separate --input=/demo-data/workflows"
    volumes:
      - ./n8n/demo-data:/demo-data
    depends_on:
      postgres:
        condition: service_healthy

  n8n:
    <<: *service-n8n
    container_name: n8n
    hostname: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    volumes:
      - n8n_storage:/home/node/.n8n
      - ./n8n/demo-data:/demo-data
      - ./n8n/shared:/data/shared
      - ./n8n/exports:/home/node/.n8n/exports
    depends_on:
      postgres:
        condition: service_healthy
      n8n-import:
        condition: service_completed_successfully

  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: qdrant
    restart: unless-stopped
    ports:
      - 6333:6333
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # No-Ollama profile services (placeholder service for explicit no-ollama mode)
  no-ollama-placeholder:
    profiles: ["no-ollama"]
    image: alpine:latest
    container_name: no-ollama-placeholder
    command: echo "Running without Ollama services. Make sure OLLAMA_HOST is set to external Ollama instance."
    networks:
      - ai_network

  # Ollama services with profiles
  ollama-cpu:
    profiles: ["cpu"]
    <<: *service-ollama

  ollama-gpu:
    profiles: ["gpu-nvidia"]
    <<: *service-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-gpu-amd:
    profiles: ["gpu-amd"]
    <<: *service-ollama
    image: ollama/ollama:rocm
    devices:
      - "/dev/kfd"
      - "/dev/dri"

  ollama-pull-llama-cpu:
    profiles: ["cpu"]
    <<: *init-ollama
    depends_on:
      - ollama-cpu

  ollama-pull-llama-gpu:
    profiles: ["gpu-nvidia"]
    <<: *init-ollama
    depends_on:
      - ollama-gpu

  ollama-pull-llama-gpu-amd:
    profiles: [gpu-amd]
    <<: *init-ollama
    image: ollama/ollama:rocm
    depends_on:
     - ollama-gpu-amd

  ai_meeting_chatbot_frontend:
    image: jccatomind/ai_meeting_chatbot_frontend:latest
    container_name: ai_meeting_chatbot_frontend
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - VITE_N8N_BASE_URL=${VITE_N8N_BASE_URL}
    networks:
      - ai_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  pgvector_data:
    driver: local
  minio_data:
    driver: local
  minio_config:
    driver: local
  n8n_storage:
    driver: local
  ollama_storage:
    driver: local
  qdrant_storage:
    driver: local
  postgres_n8n_data:
    driver: local

networks:
  ai_network:
    driver: bridge

 