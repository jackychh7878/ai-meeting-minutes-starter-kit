version: '3.8'

x-n8n: &service-n8n
  image: n8nio/n8n:latest
  networks: ['ai_network']
  environment:
    - DB_TYPE=postgresdb
    - DB_POSTGRESDB_HOST=postgres
    - DB_POSTGRESDB_PORT=5432
    - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
    - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_PERSONALIZATION_ENABLED=false
    - OLLAMA_HOST=ollama:11434
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
    - N8N_DEFAULT_BINARY_DATA_MODE=${N8N_DEFAULT_BINARY_DATA_MODE}
  env_file:
    - .env

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  networks: ['ai_network']
  restart: unless-stopped
  ports:
    - 11434:11434
  volumes:
    - ollama_storage:/root/.ollama

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  container_name: ollama-pull-llama
  networks: ['ai_network']
  volumes:
    - ollama_storage:/root/.ollama
  entrypoint: /bin/sh
  environment:
    - OLLAMA_HOST=ollama:11434
  command:
    - "-c"
    - "sleep 3; ollama pull llama3.2"

services:
  ai_meeting_backend:
    image: jccatomind/ai_meeting_backend:latest
    container_name: ai_meeting_backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - FLASK_APP=app.py
      - FLASK_ENV=production
      - GUNICORN_CMD_ARGS=--timeout=300 --workers=2 --threads=4 --worker-class=gthread
      - AZURE_STT_API_KEY=${AZURE_STT_API_KEY}
      - FANOLAB_HOST=${FANOLAB_HOST}
      - FANOLAB_API_KEY=${FANOLAB_API_KEY}
      - AZURE_POSTGRES_CONNECTION=${AZURE_POSTGRES_CONNECTION}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - ON_PREMISES_MODE=${ON_PREMISES_MODE}
      - NGROK_PUBLIC_MODE=${NGROK_PUBLIC_MODE}
      - NGROK_HOST=${NGROK_HOST}
      - NGROK_ACCESS_KEY=${NGROK_ACCESS_KEY}
      - NGROK_SECRET_KEY=${NGROK_SECRET_KEY}
      - TFLOW_HOST=${TFLOW_HOST}
      - ON_PREMISES_POSTGRES_CONNECTION=${ON_PREMISES_POSTGRES_CONNECTION}
    env_file:
      - .env
    depends_on:
      - pgvector
      - minio
      - n8n
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    networks:
      - ai_network

  pgvector:
    image: pgvector/pgvector:pg17
    container_name: pgvector
    environment:
      - POSTGRES_USER=sqladmin
      - POSTGRES_PASSWORD=P@ssw0rd
      - POSTGRES_DB=postgres
    ports:
      - "5432:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./init-schema.sql:/docker-entrypoint-initdb.d/init-schema.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sqladmin"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    networks:
      - ai_network

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
      - minio_config:/root/.minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 5s
    networks:
      - ai_network

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "5433:5432"
    volumes:
      - postgres_n8n_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - ai_network

  n8n-import:
    <<: *service-n8n
    container_name: n8n-import
    hostname: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/demo-data/credentials && n8n import:workflow --separate --input=/demo-data/workflows"
    volumes:
      - ./n8n/demo-data:/demo-data
    depends_on:
      postgres:
        condition: service_healthy

  n8n:
    <<: *service-n8n
    container_name: n8n
    hostname: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    volumes:
      - n8n_storage:/home/node/.n8n
      - ./n8n/demo-data:/demo-data
      - ./n8n/shared:/data/shared
      - ./n8n/exports:/home/node/.n8n/exports
    depends_on:
      postgres:
        condition: service_healthy
      n8n-import:
        condition: service_completed_successfully

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: unless-stopped
    ports:
      - 6333:6333
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - ai_network

  ollama-cpu:
    profiles: ["cpu"]
    <<: *service-ollama

  ollama-gpu:
    profiles: ["gpu-nvidia"]
    <<: *service-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-gpu-amd:
    profiles: ["gpu-amd"]
    <<: *service-ollama
    image: ollama/ollama:rocm
    devices:
      - "/dev/kfd"
      - "/dev/dri"

  ollama-pull-llama-cpu:
    profiles: ["cpu"]
    <<: *init-ollama
    depends_on:
      - ollama-cpu

  ollama-pull-llama-gpu:
    profiles: ["gpu-nvidia"]
    <<: *init-ollama
    depends_on:
      - ollama-gpu

  ollama-pull-llama-gpu-amd:
    profiles: [gpu-amd]
    <<: *init-ollama
    image: ollama/ollama:rocm
    depends_on:
     - ollama-gpu-amd

  ai_meeting_chatbot_frontend:
    image: jccatomind/ai_meeting_chatbot_frontend:latest
    container_name: ai_meeting_chatbot_frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - VITE_N8N_BASE_URL=${VITE_N8N_BASE_URL}
    networks:
      - ai_network

volumes:
  pgvector_data:
  minio_data:
  minio_config:
  n8n_storage:
  ollama_storage:
  qdrant_storage:
  postgres_n8n_data:

networks:
  ai_network:
    driver: bridge

 